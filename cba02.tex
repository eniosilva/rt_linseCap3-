\documentclass[conference,harvard,brazil,english]{sbatex}
\usepackage[latin1]{inputenc}
\usepackage{graphicx,url}
\usepackage{ae}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{subfigure}

%% Declaração de Operadores Matemáticos
\DeclareMathOperator{\NB}{NB}
\DeclareMathOperator{\WB}{WB}
\DeclareMathOperator{\UP}{UP}
\DeclareMathOperator{\LSF}{LSF}
\DeclareMathOperator{\CB}{CB}
\DeclareMathOperator{\exci}{exc}
\DeclareMathOperator{\vo}{v}
\DeclareMathOperator{\nv}{nv}
\DeclareMathOperator{\transp}{^T}

\makeatletter
\def\verbatim@font{\normalfont\ttfamily\footnotesize}
\makeatother
\usepackage{amsmath}
% --------------------------------------------------


\begin{document}

% CABEÇALHO

\title{Clusterização Usando Classificação Fonética}

%\author{Ênio dos Santos Silva}{enio@linse.ufsc.br}
\author{Ênio dos Santos Silva, Rui Seara}{enio@linse.ufsc.br, seara@linse.ufsc.br}
\address{LINSE -- Laboratório de Circuitos e Processamento de Sinais \\
Departamento de Engenharia Elétrica - Universidade Federal de Santa Catarina (UFSC)\\
Florianópolis, SC - Brasil}

%\author{Rui Seara}{seara@linse.ufsc.br}

\twocolumn[

\maketitle

\selectlanguage{english}
\begin{abstract}
 This work presents a.
\end{abstract}

\keywords{.}

\selectlanguage{brazil}
\begin{abstract}
 Este trabalho apresenta um.
\end{abstract}

\keywords{Reconhecimento de padrões, classificação fonética, árvore de decição.}
]
% CONTRIBUIÇÃO
\selectlanguage{brazil}

\section{Introdução}
\section{Seleção de Atributos}
\section{Algoritmo de Clusterização}
\section{Resultado e Análise de Desempenho}
\section{Conclusões e Comentários Finais}

O conjunto de sons componentes dos sinais de fala podem ser agrupados, de acordo com suas similaridades acústicas, em classes fonéticas. Tais classes representam um conjunto de características temporais e espectrais singulares. Essas singularidades são específicas de cada conjunto de sinais e garantem maior discriminação entre as diferentes classes fonéticas. Em \cite{Pulakka2007} e \cite{Jesus2001}, são descritas as propriedades acústicas dos sinais de fala. De acordo com a avaliação do comportamento de cada classe fonética quanto à distribuição de energia no domínio espectral, nota-se que, para o conjunto de classes fricativas, os componentes mais discriminativos encontram-se nas altas bandas de frequência, $S_{\UP}$, i.e., acima de $3400$ Hz e, consequentemente, além da banda de frequência originalmente considerada pela PSTN. Dessa forma, dentre as demais classes fonéticas (veja \cite{Cristofaro}), a discriminação entre fonemas das classes fricativas torna sua percepção mais difícil para os usuários de PSTNs convencionais. Assim, uma atenção especial é dada para tais classes de fonemas, resultando na proposta da Tabela~\ref{TebelaClasses}, a qual será utilizada como referência para o processo de clusterização dos sinais de fala $s_{\NB}(n)$ e $s_{\WB}(n)$.

\begin{table}[htb]
  \caption{Distribuição de classes fonéticas  para sinais de fala}\label{TebelaClasses}
  \begin{center}
% {\tt
  \begin{tabular}{|c|c|c|c|c|c|}\hline
  \multicolumn{4}{|c|}{Classes} & \multirow{2}{*}{ex.} & \multirow{2}{*}{Descrição}\\\cline{1-4}
  2&3&5&9&&\\\hline\hline
  %&&C1&$/z/$ & Fricativas vozeadas alveolares\\\hline
  \multirow{8}{*}{A1}&\multirow{4}{*}{B1}&\multirow{3}{*}{C1}&D1&$/z/$ & Fricativas vozeadas alveolares\\\cline{4-6}
     & & &D2&$/v/$ & Fricativas vozeadas labiodentais\\\cline{4-6}
     & & &D3&$/j/$ & Fricativas vozeadas palatais\\\cline{3-6}
     & &C2 &D4&$/V/$ & Demais fonemas vozeados\\\cline{2-6}
     &\multirow{4}{*}{B2}&\multirow{3}{*}{B3}&D5&$/f/$ & Fricativas não-vozeadas labiodentais\\\cline{4-6}
     & & &D6&$/s/$ & Fricativas não-vozeadas alveolares\\\cline{4-6}
     & & &D7&$/x/$ & Fricativas não-vozeadas palatais\\\cline{3-6}
     & &C4 &D8&$/U/$ & Demais fonemas não-vozeados\\\hline
  A2 &B3 &C5 &D9&$/Sil/$ & Silêncio\\\hline
  \end{tabular}
% }
  \end{center}
\end{table}
A Tabela \ref{TebelaClasses} apresenta quatro diferentes tipos de clusterização denominadas A, B, C e D, contendo duas, três, cinco e nove classes. Após o processo de clusterização e classificação fonética, a seleção de \textit{codebooks} NB e WB torna-se mais discriminativa e, consequentemente, mais apropriada para a etapa de treinamento.

\section{Classes Fonéticas}
\section{Algoritmo de Clusterização}
\subsection{Seleção de Atributos}
\section{Análise da Classificação}


O processo de treinamento aqui utilizado considera as técnicas de \textit{codebooks} duais de banda estreita $X^{\NB}_{\CB}$ e de banda alta $Y^{\UP}_{\CB}$~\cite{unno05}, criados a partir do agrupamento dos vetores de parâmetros $\mathbf{x}^{NB}$ e $\mathbf{y}^{UP}$ em classes fonéticas dispostas de acordo com a Tabela~\ref{TebelaClasses}

\begin{table}[htb]
  \caption{Distribuição de classes fonéticas  para sinais de fala}\label{TebelaClasses}
  \begin{center}
  \begin{tabular}{|c|c|}\hline
  Classes &  Descrição\\\hline\hline
    $Cl_1$& Fricativas vozeadas alveolares\\\hline
    $Cl_2$& Fricativas vozeadas labiodentais\\\hline
    $Cl_3$& Fricativas vozeadas palatais\\\hline
    $Cl_4$& Demais fonemas vozeados\\\hline
    $Cl_5$& Fricativas não-vozeadas labiodentais\\\hline
    $Cl_6$& Fricativas não-vozeadas alveolares\\\hline
    $Cl_7$& Fricativas não-vozeadas palatais\\\hline
    $Cl_8$& Demais fonemas não-vozeados\\\hline
    $Cl_9$& Silêncio\\\hline
  \end{tabular}
  \end{center}
\end{table}

Deste modo, um treinamento supervisionado é realizado e o agrupamento dos vetores de parâmetros $\mathbf{x}^{NB}$ e $\mathbf{y}^{UP}$ torna-se mais discriminativo. Assim, cada \textit{codebook} é associado a uma classe fonética específica $\phi$, isto é, 
\begin{equation}
\begin{array}{r}
Y^{\UP}_{{\CB}_{\phi}}=E\{Y^{\UP} | \phi=Cl_i\}\\ % \, \in \, \Re^9 %\, \forall \, i=1 \ldots 9
X^{\NB}_{{\CB}_{\phi}}=E\{X^{\NB} | \phi=Cl_i\} 
\end{array}, \quad \forall i \in \, [1,9]
\end{equation}

\subsection{Estimação da Classe Fonética e dos Parâmetros do Trato Vocal para ABWE}
Para a estimação das classes fonéticas, $\phi \in \{Cl_1, \ldots, Cl_9\}$, o algoritmo de árvore de decisão J48 é utilizado \cite{bookweka}, \cite{algorithmJ48}. A cada \textit{frame} de 20 ms são extraídos vetores de observação contendo os seguintes parâmetros: os 10 primeiros coeficientes de auto-correlação, a taxa de cruzamento por zero, o índice de gradiente, a energia normalizada do frame, Kurtosis local e a centróide espectral, como apresentado em ~\cite{PJaxThesis}. A partir dos vetores de observação, a árvore de decisão é consultada e a classe fonética correspondente é obtida. A abordagem de agrupamento de classes similares (veja Tabela~\ref{TebelaClasses}) aumenta a robustez quanto a erros de classificação, reduzindo eventuais imprecisões de singularidades acústicas. A robustez é garantida porque mesmo havendo falhas de classificação, as classes fonéticas estimadas não estarão tão distantes de suas versões corretas.
%Para a estimação das classes fonéticas, $\phi \in \{Cl_1, \ldots, Cl_9\}$ é utilizado o algoritmo de árvore de decisão J48~\cite{bookweka}, ~\cite{algorithmJ48}. A cada \textit{frame} de 20 ms são extraídos vetores de observação contendo os seguintes parâmetros: os 10 primeiros coeficientes de auto-correlação, a taxa de cruzamento por zero, o índice de gradiente, a energia normalizada do frame, Kurtosis local e a centróide espectral, como apresentado em ~\cite{PJaxThesis}. A partir dos vetores de observação, a árvore de decisão é consultada e a classe fonética correspondente é obtida. A abordagem de agrupamento de classes similares (veja Tabela~\ref{TebelaClasses}) aumenta a robustez quanto a erros de classificação, reduzindo eventuais imprecisões de singularidades acústicas devido às classes fonéticas estimadas, quando falhas, não estarem tão distantes de suas versões corretas.

Supõe-se aqui que $\mathbf{q}^{\UP}$ representa os vetores que caracterizam o modelo do trato vocal de banda alta, $\mathbf{q}^{\UP} \supset [\mathbf{t}, \mathbf{f}_{\LSF}]$. Assim, $\mathbf{q}^{\UP}$ é organizado em uma matriz de \textit{codewords} $\mathbf{Q}(n | Y^{\UP}_{\CB_{\phi}})$ de acordo com as suas correspondentes classes fonéticas $\phi$. Dessa maneira, para a estimação de $\hat{\mathbf{q}}_{UP}$, uma vez determinada a classe, $\phi$, do \textit{frame} do segmento de fala NB no instante $n$, as $K$ \textit{codewords} mais similares aos vetores $\mathbf{f}_{\LSF,n}$ e $\mathbf{t}_n$ do \textit{codebook} ${Y}^{\UP}_{{\CB}_{\phi}}$ são selecionadas via \textit{codebook dual} ${X}^{\NB}_{{\CB}_{\phi}}$, isto é,
\begin{equation}
\begin{array}{l}
\mathbf{Q}(n | Y^{\UP}_{\CB_{\phi}}) = \{\mathbf{q}^{\UP}_1(n|{X}^{\NB}_{{\CB}_{\phi}}),\mathbf{q}^{\UP}_2(n|{X}^{\NB}_{{\CB}_{\phi}}),..., \\
\mathbf{q}^{\UP}_{K}(n|{X}^{\NB}_{{\CB}_{\phi}})\}
\end{array}
\end{equation}
e os correspondentes vetores $\mathbf{f}_{\LSF,n}$ e $\mathbf{t}_n$ de banda alta são combinados linearmente com pesos $w$, calculados via distâncias euclidianas~\cite{unno05}, para cada \textit{codeword}. Assim,
\begin{equation}
\hat{\mathbf{q}}_{\UP}(n) = \sum_{m=1}^{K} w_m \cdot \mathbf{q}^{\UP}_{m}(n | X^{\NB}_{\CB_{\phi}}) \; \forall \; \mathbf{q}^{\UP}_m \supset [\mathbf{f}_{\LSF}, \mathbf{t}]
\end{equation}
%para
%\begin{equation}
%S_{up} \supset [\mathbf{f}_{LSF}^{up}, \mathbf{t}^{up}]
%\end{equation}
onde $\mathbf{q}^{\UP}_{m}$ representa as \textit{codewords} constituídas pelos parâmetros $\mathbf{f}_{\LSF}$ e $\mathbf{t}$ de banda alta. Assim,
\begin{equation}
\begin{array}{l}
\hat{\mathbf{q}}^{\UP}(n) \supset [\hat{\mathbf{t}}_n, \hat{\mathbf{f}}_{\LSF,n}]\\
\hat{s}_{\UP}(n) = [\hat{s}_{\UP}^{\exci}(n) * \hat{\mathbf{t}}_n] * \hat{\mathbf{f}}_{\LSF,n} \\
%\hat{s}_{\UP}(n) = \hat{s}_{\UP}^{\exci}(n) * \hat{\mathbf{q}}_{\UP}(n) \\
\hat{s}_{\WB}(n) =  \hat{s}_{\UP}(n) + s_{\NB}(n).
\end{array}
\end{equation}

\bibliography{cba02}
\end{document}